{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark libraries\n",
    "import pyspark\n",
    "from pyspark.sql.functions import max\n",
    "\n",
    "# data wrangling\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use spark! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create local spark enviroment\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the three quarters from 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.read.csv('../data/data_Q1_2019/*.csv', header=True)\n",
    "df2 = spark.read.csv('../data/data_Q2_2019/*.csv', header=True)\n",
    "df3 = spark.read.csv('../data/data_Q3_2019/*.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129\n",
      "129\n",
      "129\n"
     ]
    }
   ],
   "source": [
    "for df in [df1,df2,df3]:\n",
    "    print(len(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine 2019 dataframes together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2019 = df1.union(df2).union(df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the 4 quarters from 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.read.csv('../data/data_Q1_2018/*.csv', header=True)\n",
    "df2 = spark.read.csv('../data/data_Q2_2018/*.csv', header=True)\n",
    "df3 = spark.read.csv('../data/data_Q3_2018/*.csv', header=True)\n",
    "df4 = spark.read.csv('../data/data_Q4_2018/*.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n",
      "109\n",
      "109\n",
      "129\n"
     ]
    }
   ],
   "source": [
    "for df in [df1,df2,df3,df4]:\n",
    "    print(len(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since the columns don't match, find the missing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_df1 = df1.columns\n",
    "cols_df4 = df4.columns\n",
    "remove_traits_list = list(set(cols_df4).difference(cols_df1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_traits_list = list(set(list4).difference(list1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove missing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for trait in remove_traits_list:\n",
    "    df2 = df2.drop(trait)\n",
    "    df3 = df3.drop(trait)\n",
    "    df4 = df4.drop(trait)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n",
      "105\n",
      "105\n",
      "105\n"
     ]
    }
   ],
   "source": [
    "for df in [df1,df2,df3,df4]:\n",
    "    print(len(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine 2018 dataframes together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2018 = df1.union(df2).union(df3).union(df4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the four quarters from 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.read.csv('../data/data_Q1_2017/*.csv', header=True)\n",
    "df2 = spark.read.csv('../data/data_Q2_2017/*.csv', header=True)\n",
    "df3 = spark.read.csv('../data/data_Q3_2017/*.csv', header=True)\n",
    "df4 = spark.read.csv('../data/data_Q4_2017/*.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n",
      "95\n",
      "95\n",
      "95\n"
     ]
    }
   ],
   "source": [
    "for df in [df1,df2,df3,df4]:\n",
    "    print(len(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine the 2017 dataframes together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017 = df1.union(df2).union(df3).union(df4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the four quarters from 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.read.csv('../data/data_Q1_2016/*.csv', header=True)\n",
    "df2 = spark.read.csv('../data/data_Q2_2016/*.csv', header=True)\n",
    "df3 = spark.read.csv('../data/data_Q3_2016/*.csv', header=True)\n",
    "df4 = spark.read.csv('../data/data_Q4_2016/*.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n",
      "95\n",
      "95\n",
      "95\n"
     ]
    }
   ],
   "source": [
    "for df in [df1,df2,df3,df4]:\n",
    "    print(len(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine the 2016 dataframes together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016 = df1.union(df2).union(df3).union(df4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove extra columms and combine years into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n",
      "95\n",
      "105\n",
      "129\n"
     ]
    }
   ],
   "source": [
    "for df in [df_2016, df_2017, df_2018, df_2019]:\n",
    "    print(len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_2016 = df_2016.columns\n",
    "cols_2019 = df_2019.columns\n",
    "remove_traits_list = list(set(cols_2019).difference(cols_2016))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for trait in remove_traits_list:\n",
    "    df_2018 = df_2018.drop(trait)\n",
    "    df_2019 = df_2019.drop(trait)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n",
      "95\n",
      "95\n",
      "95\n"
     ]
    }
   ],
   "source": [
    "for df in [df_2016, df_2017, df_2018, df_2019]:\n",
    "    print(len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_2019.union(df_2018).union(df_2017).union(df_2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract max values from top five SMART attributes and convert to pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_pandas(df):\n",
    "    df = df.groupby('serial_number', 'model', 'capacity_bytes'\n",
    "              ).agg(\n",
    "                max('failure'), max('smart_9_raw'), max('smart_5_raw'), \n",
    "                max('smart_187_raw') , max('smart_197_raw'), max('smart_198_raw')\n",
    "                )\n",
    "    df = df.select(\"*\").toPandas()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save dfs as csv for easy access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = data_to_pandas(df_2019)\n",
    "# df.to_csv(r'./hard_drives_2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = data_to_pandas(df_2018)\n",
    "# df.to_csv(r'./hard_drives_2018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = data_to_pandas(df_2017)\n",
    "# df.to_csv(r'./hard_drives_2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = data_to_pandas(df_2016)\n",
    "# df.to_csv(r'./hard_drives_2016.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_to_pandas(df)\n",
    "df.to_csv(r'./hard_drives_smart_5.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Will now code everying in pandas! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 169073 entries, 0 to 169072\n",
      "Data columns (total 9 columns):\n",
      "serial_number         169072 non-null object\n",
      "model                 169073 non-null object\n",
      "capacity_bytes        169073 non-null object\n",
      "max(failure)          169073 non-null object\n",
      "max(smart_9_raw)      161975 non-null object\n",
      "max(smart_5_raw)      161851 non-null object\n",
      "max(smart_187_raw)    104189 non-null object\n",
      "max(smart_197_raw)    161841 non-null object\n",
      "max(smart_198_raw)    161841 non-null object\n",
      "dtypes: object(9)\n",
      "memory usage: 11.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serial_number</th>\n",
       "      <th>model</th>\n",
       "      <th>capacity_bytes</th>\n",
       "      <th>max(failure)</th>\n",
       "      <th>max(smart_9_raw)</th>\n",
       "      <th>max(smart_5_raw)</th>\n",
       "      <th>max(smart_187_raw)</th>\n",
       "      <th>max(smart_197_raw)</th>\n",
       "      <th>max(smart_198_raw)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>176FT026T</td>\n",
       "      <td>TOSHIBA MQ01ABF050M</td>\n",
       "      <td>500107862016</td>\n",
       "      <td>0</td>\n",
       "      <td>9965</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17eddeea3c620010</td>\n",
       "      <td>DELLBOSS VD</td>\n",
       "      <td>480036847616</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18K0A02ZF97G</td>\n",
       "      <td>TOSHIBA MG07ACA14TA</td>\n",
       "      <td>14000519643136</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>43</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2AGHLPBY</td>\n",
       "      <td>HGST HUH721212ALN604</td>\n",
       "      <td>12000138625024</td>\n",
       "      <td>0</td>\n",
       "      <td>990</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2AGM5WEY</td>\n",
       "      <td>HGST HUH721212ALN604</td>\n",
       "      <td>12000138625024</td>\n",
       "      <td>0</td>\n",
       "      <td>978</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      serial_number                 model  capacity_bytes max(failure)  \\\n",
       "0         176FT026T   TOSHIBA MQ01ABF050M    500107862016            0   \n",
       "1  17eddeea3c620010           DELLBOSS VD    480036847616            0   \n",
       "2      18K0A02ZF97G   TOSHIBA MG07ACA14TA  14000519643136            1   \n",
       "3          2AGHLPBY  HGST HUH721212ALN604  12000138625024            0   \n",
       "4          2AGM5WEY  HGST HUH721212ALN604  12000138625024            0   \n",
       "\n",
       "  max(smart_9_raw) max(smart_5_raw) max(smart_187_raw) max(smart_197_raw)  \\\n",
       "0             9965                0               None                  0   \n",
       "1             None             None               None               None   \n",
       "2               99               43               None                  0   \n",
       "3              990                0               None                  0   \n",
       "4              978                0               None                  0   \n",
       "\n",
       "  max(smart_198_raw)  \n",
       "0                  0  \n",
       "1               None  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
